{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5347e86d",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d176543b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mke37/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForTokenClassification # Import AutoTokenizer and BertForTokenClassification from the transformers library for NLP tasks.\n",
    "import torch # Import the PyTorch library for tensor computations and deep learning.\n",
    "import numpy as np # Import NumPy for numerical operations and array manipulations.\n",
    "import argparse # Import argparse for parsing command-line arguments.\n",
    "from typing import List # Import List from the typing module for type annotations.\n",
    "from config import Config # Import Config class from the config module, used for loading and accessing configuration settings.\n",
    "# Import utility functions: read_labels (to read label data), get_label_map and get_inv_label_map (for mapping labels to indices and vice versa).\n",
    "from utils import read_labels, get_label_map, get_inv_label_map\n",
    "import argparse # Re-import argparse (duplicate import, not necessary).\n",
    "import sys # Import sys for interacting with the Python interpreter (e.g., command-line arguments, system exit).\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e04d08-550f-44ab-81b3-25d49222b0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "curr_sentence = []\n",
    "curr_labels = []\n",
    "\n",
    "with open(\"TestingData.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        if line != \"\\n\":\n",
    "            label = line.split()[0]\n",
    "            word = line.split()[1]\n",
    "            \n",
    "            curr_sentence.append(word)\n",
    "            curr_labels.append(label)\n",
    "        else:\n",
    "            sentences.append(curr_sentence)\n",
    "            labels.append(curr_labels)\n",
    "            curr_sentence = []\n",
    "            curr_labels = []\n",
    "            \n",
    "print(\"DONE!\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f781164",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "11.68 %\n",
      "23.36 %\n",
      "35.05 %\n",
      "46.73 %\n",
      "58.41 %\n",
      "70.09 %\n",
      "81.78 %\n",
      "93.46 %\n",
      "100 %\n"
     ]
    }
   ],
   "source": [
    "class NERPredictor:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.cfg = Config() # Initialize and load configuration settings from the Config class.\n",
    "        \n",
    "        # Read the label list from the specified file path.\n",
    "        self.label_list = read_labels('NewEntities.txt')\n",
    "        # Create mappings from labels to indices and vice versa.\n",
    "        self.label_map = get_label_map(self.label_list)\n",
    "        self.inv_label_map = get_inv_label_map(self.label_list)\n",
    "\n",
    "        # Load the pre-trained BERT model for token classification.\n",
    "        self.model = BertForTokenClassification.from_pretrained(\n",
    "            self.cfg.MODEL_NAME,\n",
    "            return_dict=True,\n",
    "            num_labels=len(self.label_map),\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False\n",
    "        )\n",
    "\n",
    "        # Load the saved model weights.\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "        # Load the tokenizer associated with the pre-trained BERT model.\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.cfg.MODEL_NAME)\n",
    "\n",
    "    def predict(self, sentences: str) -> List[str]:\n",
    "        \n",
    "        foundDecimal = False\n",
    "        \n",
    "        # Tokenize the input sentence to get input IDs.\n",
    "        input_ids = self.tokenizer.encode(sentences, return_tensors='pt')\n",
    "        # print(len(input_ids[0]), input_ids)\n",
    "        with torch.no_grad(): # Disable gradient calculations for inference.\n",
    "            self.model.to('cpu') # Ensure the model is on CPU for inference.\n",
    "            # Get model predictions for the input IDs.\n",
    "            output = self.model(input_ids)\n",
    "\n",
    "        # Convert model logits to label indices.\n",
    "        label_indices = np.argmax(output.logits.to('cpu').numpy(), axis=2)\n",
    "        # Convert input IDs back to tokens.\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "\n",
    "        new_tokens, new_labels = [], []\n",
    "\n",
    "        label_indices_0 = label_indices[0]\n",
    "        for i in range(len(tokens)):\n",
    "            token = tokens[i]\n",
    "            label_idx = label_indices_0[i]\n",
    "            # Merge subword tokens that start with \"##\".\n",
    "            # print(token, label_idx, \"DEBUG\", i)\n",
    "            \n",
    "            if foundDecimal:\n",
    "                # print(\"__________foundDecimal__________\")\n",
    "                token = \"##\" + tokens[i]\n",
    "                foundDecimal = False\n",
    "            if token.startswith(\".\") and tokens[i-1][-1].isdigit() and i != len(tokens)-2:\n",
    "                # print(\"__________foundDecimal__________\")\n",
    "                foundDecimal = True\n",
    "                token = \"##\" + tokens[i]\n",
    "                \n",
    "            if token == \"%\" or token == \"٪\" and i != 1:\n",
    "                # print(\"________foundPercentage_________\")\n",
    "                token = \"##\" + tokens[i]\n",
    "                \n",
    "            if (token == \"٬\" or token == \"٫\") and (any(char.isdigit() for char in prev_token) and any(char.isdigit() for char in tokens[i+1])):\n",
    "                # print(\"___________foundComma___________\")\n",
    "                token = \"##\" + tokens[i]\n",
    "                foundDecimal = True\n",
    "                            \n",
    "            if token.startswith(\"##\") :\n",
    "                # print(\"_____________MERGE_______________\")\n",
    "                new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "            else:\n",
    "                if input_ids[0][i] == 2 or input_ids[0][i] == 3:\n",
    "                    continue\n",
    "                # Append the label for the token to new_labels.\n",
    "                new_labels.append(self.inv_label_map[label_idx])\n",
    "                # Append the token to new_tokens.\n",
    "                new_tokens.append(token)\n",
    "                \n",
    "            prev_token = token\n",
    "            \n",
    "        # Return the list of labels corresponding to each token in the input.\n",
    "        return new_labels\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    predictor = NERPredictor(model_path='JuneModel.pt')\n",
    "\n",
    "#     index = 320\n",
    "    \n",
    "#     predicted_labels = predictor.predict(' '.join(testSentences[index]))\n",
    "#     print()\n",
    "#     print(predicted_labels)\n",
    "#     for token, label in zip(testSentences[index], predicted_labels):\n",
    "#         print(label, token)\n",
    "        \n",
    "        \n",
    "#     for i in range(0, len(testSentences[index])):\n",
    "#         print(testSentences[index][i], predicted_labels[i])\n",
    "        \n",
    "#     for i in range(len(testSentences[index]), len(predicted_labels)):\n",
    "#         print(predicted_labels[i])\n",
    "        \n",
    "#     print(len(predicted_labels))\n",
    "\n",
    "    labelsPredictedArray = []\n",
    "    for i in range(0, len(sentences)):\n",
    "        predicted_labels = predictor.predict(' '.join(sentences[i]))\n",
    "        labelsPredictedArray.append(predicted_labels)\n",
    "        if i % 100 == 0:\n",
    "            print(round((i/len(sentences)) * 100, 2), \"%\")\n",
    "        \n",
    "    print(\"100 %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02940869-53e2-4e55-846c-331be155681a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dill.dump_session('fixedBugs_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c444a81-eeba-4d5b-9896-ba6b5be02ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted (58)       Word                 True (58)           \n",
      "--------------------------------------------------------\n",
      "OUTSIDE              وتقدر                OUTSIDE             \n",
      "OUTSIDE              إستهلاكات            OUTSIDE             \n",
      "OUTSIDE              الطاقة               OUTSIDE             \n",
      "OUTSIDE              المتجددة             OUTSIDE             \n",
      "OUTSIDE              في                   OUTSIDE             \n",
      "OUTSIDE              عام                  B-Date              \n",
      "B-Date               2015                 I-Date              \n",
      "OUTSIDE              حسب                  OUTSIDE             \n",
      "OUTSIDE              ترتيب                OUTSIDE             \n",
      "OUTSIDE              المساهمة             OUTSIDE             \n",
      "OUTSIDE              حيث                  OUTSIDE             \n",
      "OUTSIDE              تمثل                 OUTSIDE             \n",
      "OUTSIDE              الكتلة               OUTSIDE             \n",
      "OUTSIDE              الحيوية              OUTSIDE             \n",
      "OUTSIDE              الخشب                OUTSIDE             \n",
      "OUTSIDE              والنفايات            OUTSIDE             \n",
      "OUTSIDE              الخبز                B-Food              \n",
      "OUTSIDE              53٪                  OUTSIDE             \n",
      "OUTSIDE              والطاقة              OUTSIDE             \n",
      "OUTSIDE              الكهرومائية          OUTSIDE             \n",
      "OUTSIDE              19.2٪                OUTSIDE             \n",
      "OUTSIDE              والرياح              OUTSIDE             \n",
      "OUTSIDE              10.7٪                OUTSIDE             \n",
      "OUTSIDE              والطاقة              OUTSIDE             \n",
      "OUTSIDE              الكهروضوئية          OUTSIDE             \n",
      "OUTSIDE              5.1٪                 OUTSIDE             \n",
      "OUTSIDE              والغاز               OUTSIDE             \n",
      "OUTSIDE              الحيوي               OUTSIDE             \n",
      "OUTSIDE              4.7٪                 OUTSIDE             \n",
      "OUTSIDE              والمياه              OUTSIDE             \n",
      "OUTSIDE              الساخنة              OUTSIDE             \n",
      "OUTSIDE              الشمسية              OUTSIDE             \n",
      "OUTSIDE              3.8٪                 OUTSIDE             \n",
      "OUTSIDE              والوقود              OUTSIDE             \n",
      "OUTSIDE              الحيوي               OUTSIDE             \n",
      "OUTSIDE              3.6٪                 OUTSIDE             \n",
      "OUTSIDE              وتمثل                OUTSIDE             \n",
      "OUTSIDE              الطاقة               OUTSIDE             \n",
      "OUTSIDE              الحيوية              OUTSIDE             \n",
      "OUTSIDE              مجموع                OUTSIDE             \n",
      "OUTSIDE              الطاقة               OUTSIDE             \n",
      "OUTSIDE              المستمدة             OUTSIDE             \n",
      "OUTSIDE              من                   OUTSIDE             \n",
      "OUTSIDE              المواد               OUTSIDE             \n",
      "OUTSIDE              النباتية             OUTSIDE             \n",
      "OUTSIDE              61.3٪                OUTSIDE             \n",
      "OUTSIDE              جول                  OUTSIDE             \n",
      "OUTSIDE              من                   OUTSIDE             \n",
      "OUTSIDE              إجمالي               OUTSIDE             \n",
      "OUTSIDE              استهلاك              OUTSIDE             \n",
      "OUTSIDE              الطاقة               OUTSIDE             \n",
      "OUTSIDE              المتجددة             OUTSIDE             \n",
      "OUTSIDE              في                   OUTSIDE             \n",
      "B-Country            أستراليا             B-Country           \n",
      "OUTSIDE              في                   OUTSIDE             \n",
      "OUTSIDE              عام                  OUTSIDE             \n",
      "B-Date               2015                 B-Date              \n",
      "OUTSIDE              .                    OUTSIDE             \n"
     ]
    }
   ],
   "source": [
    "index = 676\n",
    "print(\"{:<20} {:<20} {:<20}\".format(\"Predicted (\" + str(len(labelsPredictedArray[index])) + \")\", \"Word\", \"True (\" + str(len(labels[index])) + \")\"))\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "\n",
    "for i in range(0, len(labels[index])):\n",
    "    print(\"{:<20} {:<20} {:<20}\".format(labelsPredictedArray[index][i], sentences[index][i], labels[index][i]))\n",
    "for i in range(len(labels[index]), len(labelsPredictedArray[index])):\n",
    "    print(labelsPredictedArray[index][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c32e69e5-5c4e-4021-848c-6281bc96da67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell to check how many invalid true/predicted entries we have\n",
    "z = 0\n",
    "for i in range(0, len(labels)):\n",
    "    if len(labels[i]) != len(labelsPredictedArray[i]):\n",
    "        # print(len(trueLabels[i]), len(labelsPredictedArray[i]))\n",
    "        z+=1\n",
    "        print(i)\n",
    "        # for j in range(0, len(trueLabels[i])):\n",
    "            # print(trueLabels[i][j], labelsPredictedArray[i][j])\n",
    "        # print(trueLabels[i], labelsPredictedArray[i])\n",
    "        print()\n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "print(\"Z:\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125a26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.load_session('fixedBugs_env.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
