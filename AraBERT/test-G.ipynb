{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36349502",
   "metadata": {},
   "source": [
    "# Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d692af-d9c2-4e11-bdaf-38caa6f46491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1fc1a9d-75a3-4d5c-a331-7efd151896de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mke37/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 27268 , Sentences: 27268 , Tags: 27268\n",
      "Data: 856 , Sentences: 856 , Tags: 856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 54/54 [00:07<00:00,  6.95it/s]\n",
      "/home/mke37/.local/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OUTSIDE seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.8921698113207547\n",
      " Precision: 0.6338924233661076\n",
      " Recall: 0.4756944444444444\n",
      " F1: 0.5435159930572775\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertForTokenClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from config import Config\n",
    "from cleaning import DataReader\n",
    "from utils import compute_metrics, read_labels, get_label_map, get_inv_label_map\n",
    "from preprocess import NERDataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, test_dataset_path):\n",
    "        self.cfg = Config()\n",
    "        \n",
    "        self.device = self.cfg.device \n",
    "\n",
    "        self.data_reader = DataReader(\"TrainingG_Data.txt\")\n",
    "\n",
    "        self.data, _, _ = self.data_reader.read_data_bert()\n",
    "\n",
    "        self.label_list = read_labels('NewEntities.txt')\n",
    "\n",
    "        self.label_map = get_label_map(self.label_list)\n",
    "        self.inv_label_map = get_inv_label_map(self.label_list)\n",
    "\n",
    "        self.test_data_reader = DataReader(test_dataset_path)\n",
    "        self.test_data, _, _ = self.test_data_reader.read_data_bert()\n",
    "\n",
    "        self.test_dataset = NERDataset(\n",
    "            texts=[x[0] for x in self.test_data],  # Extract texts from the test data.\n",
    "            tags=[x[1] for x in self.test_data],  # Extract tags (labels) from the test data.\n",
    "            label_list=self.label_list,  # Provide the list of labels.\n",
    "            model_name=self.cfg.MODEL_NAME,  # Model name from the configuration, used for tokenizer initialization.\n",
    "            max_length=self.cfg.MAX_LEN  # Maximum sequence length from the configuration.\n",
    "        )\n",
    "\n",
    "    def model_test(self, test_dl, model, device):\n",
    "        with torch.no_grad():  # Disable gradient calculations for inference.\n",
    "            model.to(device)  # Move the model to the specified device (CPU or GPU).\n",
    "            model.eval()  # Set the model to evaluation mode.\n",
    "            final_loss = 0  # Initialize total loss for testing.\n",
    "            all_predictions = []  # List to store all predictions.\n",
    "            all_labels = []  # List to store all true labels.\n",
    "\n",
    "            for data in tqdm(test_dl, total=len(test_dl)):\n",
    "                input_ids = data['input_ids'].to(device)\n",
    "                attention_mask = data['attention_mask'].to(device)\n",
    "                token_type_ids = data['token_type_ids'].to(device)\n",
    "                labels = data['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids,\n",
    "                                token_type_ids=token_type_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                                labels=labels)\n",
    "\n",
    "                loss = outputs.loss\n",
    "                final_loss += loss.item()\n",
    "                all_labels.extend(labels.to('cpu').numpy())\n",
    "                all_predictions.extend(outputs.logits.to('cpu').numpy())\n",
    "\n",
    "            metrics = compute_metrics(predictions=np.asarray(all_predictions), labels=np.asarray(all_labels), inv_label_map=self.inv_label_map)\n",
    "\n",
    "            accuracy_score = metrics['accuracy_score']\n",
    "            precision = metrics['precision']\n",
    "            recall = metrics['recall']\n",
    "            f1 = metrics['f1']\n",
    "\n",
    "            print(f' Accuracy: {accuracy_score}')\n",
    "            print(f' Precision: {precision}')\n",
    "            print(f' Recall: {recall}')\n",
    "            print(f' F1: {f1}')\n",
    "            \n",
    "\n",
    "    def run(self):\n",
    "        model = BertForTokenClassification.from_pretrained(self.cfg.MODEL_NAME,\n",
    "                                                           return_dict=True,\n",
    "                                                           num_labels=len(self.label_map),\n",
    "                                                           output_attentions=False,\n",
    "                                                           output_hidden_states=False)\n",
    "\n",
    "        test_data_loader = DataLoader(dataset=self.test_dataset, batch_size=self.cfg.TEST_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "        model.load_state_dict(torch.load('JuneModel_G.pt', map_location=self.device))\n",
    "\n",
    "        self.model_test(test_dl=test_data_loader, model=model, device=self.device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_dataset_path = \"TestingData.txt\"\n",
    "    tester = Tester(test_dataset_path)\n",
    "    tester.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
